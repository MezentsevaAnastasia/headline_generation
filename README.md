# **Генерация заголовков новостных статей на русском языке**
Эксперименты проводились на основе [корпуса новостных статей](https://github.com/RossiyaSegodnya/ria_news_dataset).  

## **Статистика по корпусу**  

В [статье](https://arxiv.org/pdf/1901.07786.pdf) перечислены некоторые статистические характеристики корпуса в качестве препроцессинга тексты приводились к нижнему регистру.  
Интересное замечание - в качестве бейзлайна авторы использовали выбор первого предложения соответствующей статьи и это показало неплохие и местами лучшие показатели в сравнении с Encoder-Decoder архитектурой и Universal Transformers.    
* Новостные статьи с января 2010 до декабря 2014;  
* Всего 1003869 статей;  
* Средняя длина заголовка - 9.5 слов;  
* Средняя длина текста статьи - 315.6 слов.    

В заголовках статей точку в конце предложения опускают, а остальные знаки препинания могут сохранятся. При использовании метрики ROUGE заголовки сравниваются потокенно, а любое предложение содержит в конце точку или другой знак препинания. 
Вычисление подобной статистики поможет понять как правильнее обрабатывать тексты для более корректного подсчёта метрик.  В данном корпусе статей статистика такая:

| Знак  | Количество упоминаний |
| ------------- | ------------- |
|вопросительный знак|2369|
|точка| 593|
|восклицательный знак| 503|
|многоточие| 125|
|двоеточие| 1|

## Описание задачи
Генерация заголовков рассматривается как суммаризация, которая по типу выходных данных делится на:
1. **Извлекающую/экстрактивная(extractive)** - нахождение наиболее важных частей текста(своеобразное выделение маркером);  
   * на основе вхождения общих слов;  
   * на основе графов, получаемых на основе матриц схожести векторных представлений предложений (например, TextRank);
   * кластеризация предложений и ранжирования по расстоянию от центра кластера (подробнее [здесь](https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1)). Библиотека, реализующая такой подход для английского языка - https://pypi.org/project/bert-extractive-summarizer/.  
   * LexRank - ранжирование по схожестви с остальными предложениями;
   * Luhn - основан на TF-IDF;
2. **Абстрактивная** - перефразирование основной мысли за счёт извлечения смысловых связей из текста. Чаще всего используются encoder-decoder архитектуры, на основе рекуррентных сетей [реализация](https://github.com/NainiShah/News-Headline-Generation) и механизма внимания.  
Подробнее в [статье](https://habr.com/ru/company/abbyy/blog/479400/) или [здесь](https://habr.com/ru/post/514540/).  
Сравнение моделей суммаризации для русского языка описано [тут](https://github.com/IlyaGusev/summarus).  

## Pipeline
1. Препроцессинг - очистка от особенностей верстки текста (html-теги, символ неразрывного пробела);  
2. Разделение на предложения с помощью nltk.sent_tokenize для русского языка;
3. Векторизация предложений Universal Sententencs Encoder(USE) с использованием кода из официального [туториала](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder.ipynb#scrollTo=weXZqLtTJY9b). Вектора заранее посчитаны в CoLab ```get_USE_vectors.ipynb``` и находятся в файле ```title_generator/data/vectors.pkl```;  
4. Кластеризация текста kmeans, количество кластеров отличалось(отражено в таблице с результатами);
5. Выбор предложения с наименьшим расстоянием до центра кластеров. 

***Была попытка сделать similarity_matrix+ранжирование на графах, но из-за высокой разрядности векторов из USE не реализовалось до конца.
   
## Результаты

Тестовое множество = первые 1000 статей. Запуск экспериментов происходит в ```title_generator/generator.py```.

|   | ROUGE-1-F | ROUGE-2-F | ROUGE-3-F |ROUGE-L-F |
| ------------- | ------------- | -------------| ------------- |------------- |
|_first sentence_| 0.19| 0.03| 0.01|0.19|
|USE + 20% от кол-во предложений| 0.13|0.04 |0.01|0.12|
|USE + 30% от кол-во предложений| 0.16|0.04 |0.01|0.16|
|USE + 40% от кол-во предложений| 0.18|0.04 |0.01|0.18|
