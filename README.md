# **Генерация заголовков новостных статей на русском языке**
Эксперименты проводились на основе [корпуса новостных статей](https://github.com/RossiyaSegodnya/ria_news_dataset).  

**Статистика по корпусу**  

В [статье](https://arxiv.org/pdf/1901.07786.pdf) перечислены некоторые статистические характеристики корпуса в качестве препроцессинга тексты приводились к нижнему регистру.  
Интересное замечание - в качестве бейзлайна авторы использовали выбор первого предложения соответствующей статьи и это показало неплохие и местами лучшие показатели в сравнении с Encoder-Decoder архитектурой и Universal Transformers.    
* Новостные статьи с января 2010 до декабря 2014;  
* Всего 1003869 статей;  
* Средняя длина заголовка - 9.5 слов;  
* Средняя длина текста статьи - 315.6 слов.    

Те же значения после препроцессинга(очистка от html-тегов).  

* Средняя длина заголовка -  слов;  
* Средняя длина текста статьи - слов.    
* Среднее количество слов в статьях -. 
* Среднее количество слов в заголовках - .

##Частота употребления слов в корпусе. 
*Без удаления стоп-слов(предлоги, союзы)
Только тексты статей

| Слово  | Количество упоминаний |
| ------------- | ------------- |
 ('новости', 1098),  ('риа', 1088),  ('россии', 845), 

| это | 12000 |  
Только заголовки

| Слово  | Количество упоминаний |
| ------------- | ------------- |
 ('рф', 120), 'россии', 43), ('молдавии', 36), ('сми', 34),('украины', 27), ('сша', 26)]

Всё вместе

| Слово  | Количество упоминаний |
| ------------- | ------------- |
|в| 12649|
|и| 6754| 
|на| 5553|

Генерация заголовков рассматривается как суммаризация, которая, в частности делится на:
1. Извлекающая/экстрактивная(extractive) - нахождение наиболее важных частей текста(своеобразное выделение маркером);  
   * на основе вхождения общих слов;  
   * на основе векторных представлений.
2. Абстрактивная - перефразирование основной мысли за счёт извлечения смысловых связей из текста. 
   * Чаще всего используются encoder-decoder архитектуры, на основе рекуррентных сетей и механизма внимания.  
Подробнее в [статье](https://habr.com/ru/company/abbyy/blog/479400/) или [здесь](https://habr.com/ru/post/514540/).  
Сравнение моделей суммаризации для русского языка описано [тут](https://github.com/IlyaGusev/summarus).  